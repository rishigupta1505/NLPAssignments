{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyML1OdvTzs0zIEGkyx6vC1m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishigupta1505/NLPAssignments/blob/master/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2BO60D_7DHC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "outputId": "2ee5aa3d-eb43-49ac-bdb2-685331ab2436"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"popular\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q4ZNqUn7mau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paragraph=\"Natural Language Processing (NLP) is a subfield of computer science, artificial intelligence, information engineering, and human-computer interaction. This field focuses on how to program computers to process and analyze large amounts of natural language data. It is difficult to perform as the process of reading and understanding languages is far more complex than it seems at first glance\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bqgf9Gv9KQp",
        "colab_type": "text"
      },
      "source": [
        "#**WORD TOKENIZER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSze4Ocz8HRD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cd45cec6-6104-41d4-c101-527ddce42fa3"
      },
      "source": [
        "from nltk import word_tokenize\n",
        "print(word_tokenize(paragraph))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'computer', 'science', ',', 'artificial', 'intelligence', ',', 'information', 'engineering', ',', 'and', 'human-computer', 'interaction', '.', 'This', 'field', 'focuses', 'on', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.', 'It', 'is', 'difficult', 'to', 'perform', 'as', 'the', 'process', 'of', 'reading', 'and', 'understanding', 'languages', 'is', 'far', 'more', 'complex', 'than', 'it', 'seems', 'at', 'first', 'glance']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-qS1LTt9Tx_",
        "colab_type": "text"
      },
      "source": [
        "#**SENTENCE TOKENIZER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfnxTmsr91yk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8cfbfb10-7b9a-41d0-91bd-41a5e90d09bd"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "print(sent_tokenize(paragraph))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Natural Language Processing (NLP) is a subfield of computer science, artificial intelligence, information engineering, and human-computer interaction.', 'This field focuses on how to program computers to process and analyze large amounts of natural language data.', 'It is difficult to perform as the process of reading and understanding languages is far more complex than it seems at first glance']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR4u9RBG-MHD",
        "colab_type": "text"
      },
      "source": [
        "#**TREE BANK TOKENIZER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ-NbcVX-m2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9591872d-342d-488f-f9cb-3deade2ef152"
      },
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer \n",
        "  \n",
        "tokenizer = TreebankWordTokenizer() \n",
        "print(tokenizer.tokenize(paragraph)) "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'computer', 'science', ',', 'artificial', 'intelligence', ',', 'information', 'engineering', ',', 'and', 'human-computer', 'interaction.', 'This', 'field', 'focuses', 'on', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data.', 'It', 'is', 'difficult', 'to', 'perform', 'as', 'the', 'process', 'of', 'reading', 'and', 'understanding', 'languages', 'is', 'far', 'more', 'complex', 'than', 'it', 'seems', 'at', 'first', 'glance']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rWrOrEC_lcQ",
        "colab_type": "text"
      },
      "source": [
        "#**REGULAR EXPRESSION TOKENIZER**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPUaPZV-_tfk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7920008-c123-4eca-a1ea-63f855efc83b"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer \n",
        "  \n",
        "tokenizer = RegexpTokenizer(\"[\\w']+\") \n",
        "text = \"Let's learn NLP running it's code on colab.\"\n",
        "tokenizer.tokenize(text) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Let's\", 'learn', 'NLP', 'running', \"it's\", 'code', 'on', 'colab']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U84SykvKBxF1",
        "colab_type": "text"
      },
      "source": [
        "#**Space Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI0QfetHB6ts",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "27f90929-2044-4c89-a40f-b6466381b5f1"
      },
      "source": [
        "from nltk import SpaceTokenizer\n",
        "\n",
        "print(SpaceTokenizer().tokenize(paragraph))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Natural', 'Language', 'Processing', '(NLP)', 'is', 'a', 'subfield', 'of', 'computer', 'science,', 'artificial', 'intelligence,', 'information', 'engineering,', 'and', 'human-computer', 'interaction.', 'This', 'field', 'focuses', 'on', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data.', 'It', 'is', 'difficult', 'to', 'perform', 'as', 'the', 'process', 'of', 'reading', 'and', 'understanding', 'languages', 'is', 'far', 'more', 'complex', 'than', 'it', 'seems', 'at', 'first', 'glance']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOSPwhXBAHfR",
        "colab_type": "text"
      },
      "source": [
        "#**STOP WORDS REMOVAL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQWW2kV7AN_z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "c4487c25-9348-4a8f-a4ab-68c7d7671bea"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "example_sent = \"Christ, he thinks, by my age I ought to know. You don’t get on by being original. You don’t get on by being bright. You don’t get on by being strong. You get on by being a subtle crook; somehow he thinks that’s what Norris is, and he feels an irrational dislike taking root, and he tries to dismiss it, because he prefers his dislikes rational, but after all, these circumstances are extreme, the cardinal in the mud, the humiliating tussle to get him back in the saddle, the talking, talking on the barge, and worse, the talking, talking on his knees, as if Wolsey’s unravelling, in a great unweaving of scarlet thread that might lead you back into a scarlet labyrinth, with a dying monster at its heart.\"\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "word_tokens = word_tokenize(example_sent)\n",
        "\n",
        "filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
        "\n",
        "filtered_sentence = []\n",
        "\n",
        "for w in word_tokens:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "\n",
        "print(\"With Stop Words:  \",word_tokens)\n",
        "print(\"Without Stop Words:  \",filtered_sentence) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With Stop Words:   ['Christ', ',', 'he', 'thinks', ',', 'by', 'my', 'age', 'I', 'ought', 'to', 'know', '.', 'You', 'don', '’', 't', 'get', 'on', 'by', 'being', 'original', '.', 'You', 'don', '’', 't', 'get', 'on', 'by', 'being', 'bright', '.', 'You', 'don', '’', 't', 'get', 'on', 'by', 'being', 'strong', '.', 'You', 'get', 'on', 'by', 'being', 'a', 'subtle', 'crook', ';', 'somehow', 'he', 'thinks', 'that', '’', 's', 'what', 'Norris', 'is', ',', 'and', 'he', 'feels', 'an', 'irrational', 'dislike', 'taking', 'root', ',', 'and', 'he', 'tries', 'to', 'dismiss', 'it', ',', 'because', 'he', 'prefers', 'his', 'dislikes', 'rational', ',', 'but', 'after', 'all', ',', 'these', 'circumstances', 'are', 'extreme', ',', 'the', 'cardinal', 'in', 'the', 'mud', ',', 'the', 'humiliating', 'tussle', 'to', 'get', 'him', 'back', 'in', 'the', 'saddle', ',', 'the', 'talking', ',', 'talking', 'on', 'the', 'barge', ',', 'and', 'worse', ',', 'the', 'talking', ',', 'talking', 'on', 'his', 'knees', ',', 'as', 'if', 'Wolsey', '’', 's', 'unravelling', ',', 'in', 'a', 'great', 'unweaving', 'of', 'scarlet', 'thread', 'that', 'might', 'lead', 'you', 'back', 'into', 'a', 'scarlet', 'labyrinth', ',', 'with', 'a', 'dying', 'monster', 'at', 'its', 'heart', '.']\n",
            "Without Stop Words:   ['Christ', ',', 'thinks', ',', 'age', 'I', 'ought', 'know', '.', 'You', '’', 'get', 'original', '.', 'You', '’', 'get', 'bright', '.', 'You', '’', 'get', 'strong', '.', 'You', 'get', 'subtle', 'crook', ';', 'somehow', 'thinks', '’', 'Norris', ',', 'feels', 'irrational', 'dislike', 'taking', 'root', ',', 'tries', 'dismiss', ',', 'prefers', 'dislikes', 'rational', ',', ',', 'circumstances', 'extreme', ',', 'cardinal', 'mud', ',', 'humiliating', 'tussle', 'get', 'back', 'saddle', ',', 'talking', ',', 'talking', 'barge', ',', 'worse', ',', 'talking', ',', 'talking', 'knees', ',', 'Wolsey', '’', 'unravelling', ',', 'great', 'unweaving', 'scarlet', 'thread', 'might', 'lead', 'back', 'scarlet', 'labyrinth', ',', 'dying', 'monster', 'heart', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjoYQmz1Anpc",
        "colab_type": "text"
      },
      "source": [
        "#**STEMMING**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hvcWKSgAsef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a32cbf0f-fa48-4e56-d137-07e486abafd4"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "porter_stemmer = PorterStemmer()\n",
        "nltk_tokens = nltk.word_tokenize(paragraph)\n",
        "for w in nltk_tokens:\n",
        "       print(\"Actual: %s  Stem: %s\"  % (w,porter_stemmer.stem(w)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual: Natural  Stem: natur\n",
            "Actual: Language  Stem: languag\n",
            "Actual: Processing  Stem: process\n",
            "Actual: (  Stem: (\n",
            "Actual: NLP  Stem: nlp\n",
            "Actual: )  Stem: )\n",
            "Actual: is  Stem: is\n",
            "Actual: a  Stem: a\n",
            "Actual: subfield  Stem: subfield\n",
            "Actual: of  Stem: of\n",
            "Actual: computer  Stem: comput\n",
            "Actual: science  Stem: scienc\n",
            "Actual: ,  Stem: ,\n",
            "Actual: artificial  Stem: artifici\n",
            "Actual: intelligence  Stem: intellig\n",
            "Actual: ,  Stem: ,\n",
            "Actual: information  Stem: inform\n",
            "Actual: engineering  Stem: engin\n",
            "Actual: ,  Stem: ,\n",
            "Actual: and  Stem: and\n",
            "Actual: human-computer  Stem: human-comput\n",
            "Actual: interaction  Stem: interact\n",
            "Actual: .  Stem: .\n",
            "Actual: This  Stem: thi\n",
            "Actual: field  Stem: field\n",
            "Actual: focuses  Stem: focus\n",
            "Actual: on  Stem: on\n",
            "Actual: how  Stem: how\n",
            "Actual: to  Stem: to\n",
            "Actual: program  Stem: program\n",
            "Actual: computers  Stem: comput\n",
            "Actual: to  Stem: to\n",
            "Actual: process  Stem: process\n",
            "Actual: and  Stem: and\n",
            "Actual: analyze  Stem: analyz\n",
            "Actual: large  Stem: larg\n",
            "Actual: amounts  Stem: amount\n",
            "Actual: of  Stem: of\n",
            "Actual: natural  Stem: natur\n",
            "Actual: language  Stem: languag\n",
            "Actual: data  Stem: data\n",
            "Actual: .  Stem: .\n",
            "Actual: It  Stem: It\n",
            "Actual: is  Stem: is\n",
            "Actual: difficult  Stem: difficult\n",
            "Actual: to  Stem: to\n",
            "Actual: perform  Stem: perform\n",
            "Actual: as  Stem: as\n",
            "Actual: the  Stem: the\n",
            "Actual: process  Stem: process\n",
            "Actual: of  Stem: of\n",
            "Actual: reading  Stem: read\n",
            "Actual: and  Stem: and\n",
            "Actual: understanding  Stem: understand\n",
            "Actual: languages  Stem: languag\n",
            "Actual: is  Stem: is\n",
            "Actual: far  Stem: far\n",
            "Actual: more  Stem: more\n",
            "Actual: complex  Stem: complex\n",
            "Actual: than  Stem: than\n",
            "Actual: it  Stem: it\n",
            "Actual: seems  Stem: seem\n",
            "Actual: at  Stem: at\n",
            "Actual: first  Stem: first\n",
            "Actual: glance  Stem: glanc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8Icpa7fA4lF",
        "colab_type": "text"
      },
      "source": [
        "#**Lemmatization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdP3PuPUA9C9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "48719bc6-9884-4aca-b42f-551ffc2d2f31"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "nltk_tokens = nltk.word_tokenize(paragraph)\n",
        "for w in nltk_tokens:\n",
        "       print(\"Actual: %s ->  Lemma: %s\"  % (w,wordnet_lemmatizer.lemmatize(w)))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual: Natural ->  Lemma: Natural\n",
            "Actual: Language ->  Lemma: Language\n",
            "Actual: Processing ->  Lemma: Processing\n",
            "Actual: ( ->  Lemma: (\n",
            "Actual: NLP ->  Lemma: NLP\n",
            "Actual: ) ->  Lemma: )\n",
            "Actual: is ->  Lemma: is\n",
            "Actual: a ->  Lemma: a\n",
            "Actual: subfield ->  Lemma: subfield\n",
            "Actual: of ->  Lemma: of\n",
            "Actual: computer ->  Lemma: computer\n",
            "Actual: science ->  Lemma: science\n",
            "Actual: , ->  Lemma: ,\n",
            "Actual: artificial ->  Lemma: artificial\n",
            "Actual: intelligence ->  Lemma: intelligence\n",
            "Actual: , ->  Lemma: ,\n",
            "Actual: information ->  Lemma: information\n",
            "Actual: engineering ->  Lemma: engineering\n",
            "Actual: , ->  Lemma: ,\n",
            "Actual: and ->  Lemma: and\n",
            "Actual: human-computer ->  Lemma: human-computer\n",
            "Actual: interaction ->  Lemma: interaction\n",
            "Actual: . ->  Lemma: .\n",
            "Actual: This ->  Lemma: This\n",
            "Actual: field ->  Lemma: field\n",
            "Actual: focuses ->  Lemma: focus\n",
            "Actual: on ->  Lemma: on\n",
            "Actual: how ->  Lemma: how\n",
            "Actual: to ->  Lemma: to\n",
            "Actual: program ->  Lemma: program\n",
            "Actual: computers ->  Lemma: computer\n",
            "Actual: to ->  Lemma: to\n",
            "Actual: process ->  Lemma: process\n",
            "Actual: and ->  Lemma: and\n",
            "Actual: analyze ->  Lemma: analyze\n",
            "Actual: large ->  Lemma: large\n",
            "Actual: amounts ->  Lemma: amount\n",
            "Actual: of ->  Lemma: of\n",
            "Actual: natural ->  Lemma: natural\n",
            "Actual: language ->  Lemma: language\n",
            "Actual: data ->  Lemma: data\n",
            "Actual: . ->  Lemma: .\n",
            "Actual: It ->  Lemma: It\n",
            "Actual: is ->  Lemma: is\n",
            "Actual: difficult ->  Lemma: difficult\n",
            "Actual: to ->  Lemma: to\n",
            "Actual: perform ->  Lemma: perform\n",
            "Actual: as ->  Lemma: a\n",
            "Actual: the ->  Lemma: the\n",
            "Actual: process ->  Lemma: process\n",
            "Actual: of ->  Lemma: of\n",
            "Actual: reading ->  Lemma: reading\n",
            "Actual: and ->  Lemma: and\n",
            "Actual: understanding ->  Lemma: understanding\n",
            "Actual: languages ->  Lemma: language\n",
            "Actual: is ->  Lemma: is\n",
            "Actual: far ->  Lemma: far\n",
            "Actual: more ->  Lemma: more\n",
            "Actual: complex ->  Lemma: complex\n",
            "Actual: than ->  Lemma: than\n",
            "Actual: it ->  Lemma: it\n",
            "Actual: seems ->  Lemma: seems\n",
            "Actual: at ->  Lemma: at\n",
            "Actual: first ->  Lemma: first\n",
            "Actual: glance ->  Lemma: glance\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}